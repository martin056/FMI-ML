{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Въведение\n",
    "\n",
    "Бях чел тази [статия](http://rstudio-pubs-static.s3.amazonaws.com/79360_850b2a69980c4488b1db95987a24867a.html) преди да говорим за `LDA` на лекциите (\"Latent Dirichlet Allocation\"). Още не го разбирам, че вътре математиката ми е над възможностите, ама нека се опитаме да го използваме, за да видим какъв резултат ще постигнем.\n",
    "\n",
    "## Какво е `LDA` накратко?\n",
    "\n",
    "*Latent Dirichlet allocation (LDA) is a topic model that generates topics based on word frequency from a set of documents. LDA is particularly useful for finding reasonably accurate mixtures of topics within a given document set.*\n",
    "\n",
    "**TL;DR Ползваме го, за да разберем за какво е текста.** Той намира някакви общи зависимости между думите, като така изкарва темата/темите на съответния текст.\n",
    "\n",
    "Искам да го пробвам, защото авторите най-вероятно имат общи теми в своите текстове. Освен това видяхме, че са живели в горе-долу различни епохи, което също може да афектира стила и темите им на писане. Но вместо да гадаем, ето какво казва Уикипедия:\n",
    "\n",
    "- [Едгар Алън По](https://bg.wikipedia.org/wiki/%D0%95%D0%B4%D0%B3%D0%B0%D1%80_%D0%90%D0%BB%D1%8A%D0%BD_%D0%9F%D0%BE#.D0.9B.D0.B8.D1.82.D0.B5.D1.80.D0.B0.D1.82.D1.83.D1.80.D0.B5.D0.BD_.D1.81.D1.82.D0.B8.D0.BB_.D0.B8_.D1.82.D0.B5.D0.BC.D0.B0.D1.82.D0.B8.D0.BA.D0.B0)\n",
    "- [Хауърд Филипс Лъвкрафт](https://bg.wikipedia.org/wiki/%D0%A5%D0%B0%D1%83%D1%8A%D1%80%D0%B4_%D0%9B%D1%8A%D0%B2%D0%BA%D1%80%D0%B0%D1%84%D1%82#.D0.91.D0.B8.D0.B1.D0.BB.D0.B8.D0.BE.D0.B3.D1.80.D0.B0.D1.84.D0.B8.D1.8F)\n",
    "- [Мери Уолстонкрафт Шели](https://bg.wikipedia.org/wiki/%D0%9C%D0%B5%D1%80%D0%B8_%D0%A8%D0%B5%D0%BB%D0%B8#.D0.A2.D0.B2.D0.BE.D1.80.D0.B1.D0.B8_.D0.BD.D0.B0_.D0.9C.D0.B5.D1.80.D0.B8_.D0.A8.D0.B5.D0.BB.D0.B8)\n",
    "\n",
    "### Или с 2 думи:\n",
    "\n",
    "- Едгар Алън По - смъртта, включително физически знаци, ефектите от разлагането, преждевременното погребение, съживяване на мъртвите и скръбта\n",
    "- Хауърд Филипс Лъвкрафт - Ктхулу\n",
    "- Мери Уолстонкрафт Шели - Франкенщайн\n",
    "\n",
    "\n",
    "![wtf](https://i.giphy.com/media/V1gFqXnfRpVxS/giphy.webp)\n",
    "*Нормални автори нямаше ли!?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Да си заредим данните първо."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19579, 2) (8392, 1) (8392, 3)\n",
      "{'author'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv(\"data/train.zip\", index_col=['id'])\n",
    "test = pd.read_csv(\"data/test.zip\", index_col=['id'])\n",
    "sample_submission = pd.read_csv(\"data/sample_submission.zip\", index_col=['id'])\n",
    "\n",
    "print(train.shape, test.shape, sample_submission.shape)\n",
    "print(set(train.columns) - set(test.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Нека си направим план\n",
    "\n",
    "Какво да направим, че да се справим оптимално добре?\n",
    "\n",
    "Първо, трябва да отбележим, че `LDA` минава доста бавно и трябва внимателно да подбираме стъпките, които правим (че в момента на писане на домашното е събота и имам далеч по-приятни неща за \"чакане\" :D)\n",
    "\n",
    "## План\n",
    "1. Нека лематизираме (`lemmatization`) думите в текста първо. По време на лекцията ползвахме \"стематизация\" (`stemming`), та реших да вкарам нещо ново. *Тези готини думи едва ли се пишат така на български...*\n",
    "2. Да махнем `stop-words`\n",
    "3. `LDA` в scikit-learn очаква да му подадем вектор от думите, ама да сме ги минали първо през `CountVectorizer` или `TfidfVectorizer` (или някакъв друг), за да може да работи. Това е добре защото, направо можем да си `Pipeline`-нем плана на действие. Ако сте видели статията от по-горе (което не сте направили) сте видели, че използват друга библиоетка (`genism`), където `LDA` очаква да му се подаде списък със самите думи от документа. *Бях отделил около половин ден, за да докарам такъв тип данни до `LDA` и да го подкарам в scikit-learn, но естествено нямаше как да стане. \"Четете си документацията!\" :(*\n",
    "4. Целта на предните ни 2 точки беше да направим т.нар. \"bag-of-words\". С други думи на `LDA` му трябва някой да му \"токенизира\" думите. Когато вече имаме вектора от текста можем спокойно да използваме `LatentDirichletAllocation`\n",
    "5. Да изсипем всички това към някакъв класификатор. Ще пробваме с `LogisticRegression` или някакво `SVC`. Накрая ще пробвам и с `MultinomialNB`, както направихме в лекцията, че поради някаква причина naive Bayes класификаториите най-добре се справят с текстове (или поне така Лъчо и някакви хора в SO казват).\n",
    "\n",
    "Ето една [статия](http://sebastianraschka.com/Articles/2014_naive_bayes_1.html), която описва детайлно NB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нека започнем да изпълняваме стъпките. Ще си направим една функция, която прави стъпки 1. и 2. Нещо такова:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(text):\n",
    "    def remove_stop_words(tokens):\n",
    "        pass\n",
    "    \n",
    "    def lemmatize():\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "За да махнем \"стоп-думите\" ще изпозлваме [тази библиотека](https://pypi.python.org/pypi/stop-words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stop_words import get_stop_words\n",
    "\n",
    "\n",
    "def prepare(df):\n",
    "    def remove_stop_words(tokens):\n",
    "        english_stop_words = get_stop_words('en')\n",
    "\n",
    "        return [token for token in tokens if token not in english_stop_words]\n",
    "\n",
    "    def lemmatize():\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сега лематизираме. Първо ще го пробвам да видим какво става, че досега не сме го използвали."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/martin056/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'process,',\n",
       " 'however,',\n",
       " 'afforded',\n",
       " 'me',\n",
       " 'no',\n",
       " 'mean',\n",
       " 'of',\n",
       " 'ascertaining',\n",
       " 'the',\n",
       " 'dimension',\n",
       " 'of',\n",
       " 'my',\n",
       " 'dungeon;',\n",
       " 'a',\n",
       " 'I',\n",
       " 'might',\n",
       " 'make',\n",
       " 'it',\n",
       " 'circuit,',\n",
       " 'and',\n",
       " 'return',\n",
       " 'to',\n",
       " 'the',\n",
       " 'point',\n",
       " 'whence',\n",
       " 'I',\n",
       " 'set',\n",
       " 'out,',\n",
       " 'without',\n",
       " 'being',\n",
       " 'aware',\n",
       " 'of',\n",
       " 'the',\n",
       " 'fact;',\n",
       " 'so',\n",
       " 'perfectly',\n",
       " 'uniform',\n",
       " 'seemed',\n",
       " 'the',\n",
       " 'wall.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "text = train.iloc[0]['text']\n",
    "\n",
    "[lemmatizer.lemmatize(token) for token in text.split()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Супер\n",
    "\n",
    "Само че открихме няколко проблема:\n",
    "  - `.lower()` на думите\n",
    "  - сами трябва да се оправим с разликата между глаголи и съществителни (\"meeting\" например).\n",
    "  - `.split()` не е чак толкова умно и не се оправя с препинателни знаци\n",
    "\n",
    "\n",
    "### Решения\n",
    "- Първият проблем е ясен\n",
    "- За втория открих нещо наречено `pos_tag` в `nltk` и ще се опитаме да го използваме\n",
    "- За третия - `RegexpTokenizer`\n",
    "\n",
    "Да видим какво ще ни даде `pos_tag` с примера от преди малко."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('This', 'DT'),\n",
       " ('process,', 'NN'),\n",
       " ('however,', 'NN'),\n",
       " ('afforded', 'VBD'),\n",
       " ('me', 'PRP'),\n",
       " ('no', 'DT'),\n",
       " ('mean', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('ascertaining', 'VBG'),\n",
       " ('the', 'DT'),\n",
       " ('dimension', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('my', 'PRP$'),\n",
       " ('dungeon;', 'NN'),\n",
       " ('a', 'DT'),\n",
       " ('I', 'PRP'),\n",
       " ('might', 'MD'),\n",
       " ('make', 'VB'),\n",
       " ('it', 'PRP'),\n",
       " ('circuit,', 'JJ'),\n",
       " ('and', 'CC'),\n",
       " ('return', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('point', 'NN'),\n",
       " ('whence', 'NN'),\n",
       " ('I', 'PRP'),\n",
       " ('set', 'VBP'),\n",
       " ('out,', 'RB'),\n",
       " ('without', 'IN'),\n",
       " ('being', 'VBG'),\n",
       " ('aware', 'JJ'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('fact;', 'NNS'),\n",
       " ('so', 'RB'),\n",
       " ('perfectly', 'RB'),\n",
       " ('uniform', 'JJ'),\n",
       " ('seemed', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('wall.', 'NN')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "text = train.iloc[0]['text']\n",
    "\n",
    "nltk.pos_tag([lemmatizer.lemmatize(token) for token in text.split()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Браво nltk](https://i.giphy.com/media/8RxCFgu88jUbe/giphy.webp)\n",
    "\n",
    "Мерси много, `nltk`! Порових се малко в SO и ето решението..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this\n",
      "process,\n",
      "however,\n",
      "afford\n",
      "me\n",
      "no\n",
      "mean\n",
      "of\n",
      "ascertain\n",
      "the\n",
      "dimension\n",
      "of\n",
      "my\n",
      "dungeon;\n",
      "a\n",
      "i\n",
      "might\n",
      "make\n",
      "it\n",
      "circuit,\n",
      "and\n",
      "return\n",
      "to\n",
      "the\n",
      "point\n",
      "whence\n",
      "i\n",
      "set\n",
      "out,\n",
      "without\n",
      "be\n",
      "aware\n",
      "of\n",
      "the\n",
      "fact;\n",
      "so\n",
      "perfectly\n",
      "uniform\n",
      "seem\n",
      "the\n",
      "wall.\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "    \n",
    "tokens_and_tags = nltk.pos_tag([lemmatizer.lemmatize(token).lower() for token in text.split()])\n",
    "\n",
    "for token, tag in tokens_and_tags:\n",
    "    print(lemmatizer.lemmatize(token, get_wordnet_pos(tag)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тези препинателни знаци, малко ме притесняват. Дайте да ги махнем!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'process', 'however', 'afforded', 'me', 'no', 'means', 'of', 'ascertaining', 'the', 'dimensions', 'of', 'my', 'dungeon', 'as', 'I', 'might', 'make', 'its', 'circuit', 'and', 'return', 'to', 'the', 'point', 'whence', 'I', 'set', 'out', 'without', 'being', 'aware', 'of', 'the', 'fact', 'so', 'perfectly', 'uniform', 'seemed', 'the', 'wall']\n",
      "['They', 'still', 'appeared', 'in', 'public', 'together', 'and', 'lived', 'under', 'the', 'same', 'roof']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "tokenizer = RegexpTokenizer(r\"'?\\b[0-9A-Za-z'-]+\\b'?\")  # matches words and words with apostrophes\n",
    "\n",
    "tokens1 = tokenizer.tokenize(train.iloc[0]['text'])\n",
    "tokens2 = tokenizer.tokenize(train.iloc[100]['text'])\n",
    "\n",
    "print(tokens1)\n",
    "print(tokens2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сега сме щастливи\n",
    "\n",
    "Време е да комбинираме всичко задно!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stop_words import get_stop_words\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "def prepare(text):\n",
    "    def tokenize():\n",
    "        return tokenizer.tokenize(text)\n",
    "\n",
    "    def remove_stop_words(tokens):\n",
    "        english_stop_words = get_stop_words('en')\n",
    "\n",
    "        return [token for token in tokens if token not in english_stop_words]\n",
    "\n",
    "    def lemmatize(tokens):\n",
    "        lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "        tokens_and_tags = nltk.pos_tag(tokens)\n",
    "        \n",
    "        lemmas = []\n",
    "\n",
    "        for token, tag in tokens_and_tags:\n",
    "            lemma = lemmatizer.lemmatize(token.lower(), get_wordnet_pos(tag))\n",
    "            lemmas.append(lemma)\n",
    "            \n",
    "        return lemmas\n",
    "    \n",
    "    tokens = tokenize()\n",
    "    tokens = remove_stop_words(tokens)\n",
    "    \n",
    "    lemmas = lemmatize(tokens)\n",
    "    \n",
    "    return \" \".join(lemmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Хайде да използваме нашата красива функция"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id26305</th>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>this process however afford mean ascertain dim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id17569</th>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>it never occur fumble might mere mistake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id11008</th>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>in left hand gold snuff box caper hill cut man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id27763</th>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>how lovely spring a looked windsor terrace six...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id12958</th>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>find nothing else even gold superintendent aba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id22965</th>\n",
       "      <td>A youth passed in solitude, my best years spen...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>a youth pass solitude best year spend gentle f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id09674</th>\n",
       "      <td>The astronomer, perhaps, at this point, took r...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>the astronomer perhaps point take refuge sugge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id13515</th>\n",
       "      <td>The surcingle hung in ribands from my body.</td>\n",
       "      <td>EAP</td>\n",
       "      <td>the surcingle hung ribands body</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id19322</th>\n",
       "      <td>I knew that you could not say to yourself 'ste...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>i know say 'stereotomy' without bring think at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id00912</th>\n",
       "      <td>I confess that neither the structure of langua...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>i confess neither structure languages code gov...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text author  \\\n",
       "id                                                                  \n",
       "id26305  This process, however, afforded me no means of...    EAP   \n",
       "id17569  It never once occurred to me that the fumbling...    HPL   \n",
       "id11008  In his left hand was a gold snuff box, from wh...    EAP   \n",
       "id27763  How lovely is spring As we looked from Windsor...    MWS   \n",
       "id12958  Finding nothing else, not even gold, the Super...    HPL   \n",
       "id22965  A youth passed in solitude, my best years spen...    MWS   \n",
       "id09674  The astronomer, perhaps, at this point, took r...    EAP   \n",
       "id13515        The surcingle hung in ribands from my body.    EAP   \n",
       "id19322  I knew that you could not say to yourself 'ste...    EAP   \n",
       "id00912  I confess that neither the structure of langua...    MWS   \n",
       "\n",
       "                                            processed_text  \n",
       "id                                                          \n",
       "id26305  this process however afford mean ascertain dim...  \n",
       "id17569           it never occur fumble might mere mistake  \n",
       "id11008  in left hand gold snuff box caper hill cut man...  \n",
       "id27763  how lovely spring a looked windsor terrace six...  \n",
       "id12958  find nothing else even gold superintendent aba...  \n",
       "id22965  a youth pass solitude best year spend gentle f...  \n",
       "id09674  the astronomer perhaps point take refuge sugge...  \n",
       "id13515                    the surcingle hung ribands body  \n",
       "id19322  i know say 'stereotomy' without bring think at...  \n",
       "id00912  i confess neither structure languages code gov...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train = train.copy()\n",
    "\n",
    "new_train['processed_text'] = new_train.apply(lambda r: prepare(r['text']), axis=1)\n",
    "\n",
    "new_train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.giphy.com/media/mHEes6Quf8XK0/giphy.webp)\n",
    "\n",
    "## Време е да се гмурнем в по-дълбокото ...\n",
    "\n",
    "Първо да видим какъв резултат ще изкараме без да използваме `LDA` (демек **baseline model**). Ще използваме `CountVectorizer` + `LinearSVC`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.77619485,  0.78455409,  0.78252874])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('features', CountVectorizer()),\n",
    "    ('clf', LinearSVC())\n",
    "])\n",
    "\n",
    "cross_val_score(pipeline, new_train.processed_text, train.author, cv=3, n_jobs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Да си поиграем малко\n",
    "\n",
    "Искам да видя какво се случва, ако използвам различни класификатори - ей така, за идеята, а и после ще ми е по-леско, когато напасвам хиперпараметрите. Ще ползваме и `neg_log_loss`, защото такова е заданието. **Хубаво е всички класификатори, които ползваме да имат `predict_proba()`, че иначе ще трябва да я пишем сами..**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.47719056 -0.46267412 -0.45622925]\n",
      "CountVectorizer + MultinomialNB scored: -0.46536464628356417 with std: 0.008766350399386022\n",
      "[-0.50442829 -0.49519917 -0.48903599]\n",
      "CountVectorizer + LogisticRegression scored: -0.49622114930192 with std: 0.0063252942089223226\n",
      "[-1.52406287 -1.64368489 -1.60907883]\n",
      "CountVectorizer + RandomForestClassifier scored: -1.592275530321652 with std: 0.0502601243228477\n",
      "[-0.6064134  -0.60352745 -0.60022146]\n",
      "TfidfVectorizer + MultinomialNB scored: -0.6033874375047138 with std: 0.002529784953187279\n",
      "[-0.6229566  -0.6184584  -0.61262533]\n",
      "TfidfVectorizer + LogisticRegression scored: -0.6180134462785358 with std: 0.0042294424652843925\n",
      "[-1.61736905 -1.64970077 -1.49802899]\n",
      "TfidfVectorizer + RandomForestClassifier scored: -1.588366270859846 with std: 0.06522756556756859\n"
     ]
    }
   ],
   "source": [
    "for vec in [CountVectorizer, TfidfVectorizer]:\n",
    "    for clf in [MultinomialNB, LogisticRegression, RandomForestClassifier]:\n",
    "\n",
    "        pipeline = Pipeline([\n",
    "            ('vec', vec()),\n",
    "            ('clf', clf())\n",
    "        ])\n",
    "\n",
    "        score_arr = cross_val_score(pipeline,\n",
    "                                    new_train.processed_text,\n",
    "                                    train.author,\n",
    "                                    cv=3, \n",
    "                                    n_jobs=3,\n",
    "                                    scoring='neg_log_loss')\n",
    "\n",
    "        print(score_arr)\n",
    "\n",
    "        msg = \"{vec} + {clf} scored: {score} with std: {std}\".format(vec=vec.__name__,\n",
    "                                                                     clf=clf.__name__,\n",
    "                                                                     score=score_arr.mean(),\n",
    "                                                                     std=score_arr.std())\n",
    "        print(msg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SVC  scored:  -0.766141513098  witf std:  0.0109908929665**\n",
    "Това е и резултатът на `SVC`-то + `CountVecotrizer`, ама на него му трябва `probability=True` при инициализацията, а мина за 7 минути и не искам да го пускам пак.\n",
    "\n",
    "\n",
    "## Да се опитаме да анализираме резултатите\n",
    "\n",
    "Очевидно имаме победител - `MultinomialNB` + `CountVectorizer`.\n",
    "\n",
    "Добре, за `NB` беше очаквано, понеже работим с текстове. Но защо `CountVectorizer` се справи по-добре от `TfidfVectorizer`? На лекцията изпозлвахме именно `Tfidf`.\n",
    "\n",
    "Ще продължа да използвам и двете, за да видя какво ще излезе. Но този път с подобрение на хиперпараметрите."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "def report(results, n_top=5):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters:\")\n",
    "            pprint(results['params'][candidate])\n",
    "            print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CountVectorizer\n",
      "Model with rank: 1\n",
      "Mean validation score: -0.479 (std: 0.010)\n",
      "Parameters:\n",
      "{'clf__alpha': 2,\n",
      " 'vec__analyzer': 'word',\n",
      " 'vec__max_df': 0.5,\n",
      " 'vec__min_df': 3,\n",
      " 'vec__ngram_range': (1, 2)}\n",
      "\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: -0.479 (std: 0.010)\n",
      "Parameters:\n",
      "{'clf__alpha': 2,\n",
      " 'vec__analyzer': 'word',\n",
      " 'vec__max_df': 1.0,\n",
      " 'vec__min_df': 3,\n",
      " 'vec__ngram_range': (1, 2)}\n",
      "\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: -0.480 (std: 0.011)\n",
      "Parameters:\n",
      "{'clf__alpha': 1,\n",
      " 'vec__analyzer': 'word',\n",
      " 'vec__max_df': 0.6,\n",
      " 'vec__min_df': 2,\n",
      " 'vec__ngram_range': (1, 3)}\n",
      "\n",
      "\n",
      "Model with rank: 4\n",
      "Mean validation score: -0.488 (std: 0.011)\n",
      "Parameters:\n",
      "{'clf__alpha': 1,\n",
      " 'vec__analyzer': 'word',\n",
      " 'vec__max_df': 0.6,\n",
      " 'vec__min_df': 3,\n",
      " 'vec__ngram_range': (1, 2)}\n",
      "\n",
      "\n",
      "Model with rank: 5\n",
      "Mean validation score: -0.498 (std: 0.007)\n",
      "Parameters:\n",
      "{'clf__alpha': 2,\n",
      " 'vec__analyzer': 'word',\n",
      " 'vec__max_df': 0.8,\n",
      " 'vec__min_df': 5,\n",
      " 'vec__ngram_range': (1, 1)}\n",
      "\n",
      "\n",
      "Model with rank: 5\n",
      "Mean validation score: -0.498 (std: 0.007)\n",
      "Parameters:\n",
      "{'clf__alpha': 2,\n",
      " 'vec__analyzer': 'word',\n",
      " 'vec__max_df': 0.9,\n",
      " 'vec__min_df': 5,\n",
      " 'vec__ngram_range': (1, 1)}\n",
      "\n",
      "\n",
      "Using TfidfVectorizer\n",
      "Model with rank: 1\n",
      "Mean validation score: -0.496 (std: 0.004)\n",
      "Parameters:\n",
      "{'clf__alpha': 0.1,\n",
      " 'vec__analyzer': 'word',\n",
      " 'vec__max_df': 1.0,\n",
      " 'vec__min_df': 5,\n",
      " 'vec__ngram_range': (1, 2)}\n",
      "\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: -0.498 (std: 0.004)\n",
      "Parameters:\n",
      "{'clf__alpha': 0.01,\n",
      " 'vec__analyzer': 'word',\n",
      " 'vec__max_df': 1.0,\n",
      " 'vec__min_df': 5,\n",
      " 'vec__ngram_range': (1, 1)}\n",
      "\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: -0.504 (std: 0.003)\n",
      "Parameters:\n",
      "{'clf__alpha': 0.1,\n",
      " 'vec__analyzer': 'word',\n",
      " 'vec__max_df': 0.9,\n",
      " 'vec__min_df': 5,\n",
      " 'vec__ngram_range': (1, 1)}\n",
      "\n",
      "\n",
      "Model with rank: 4\n",
      "Mean validation score: -0.535 (std: 0.003)\n",
      "Parameters:\n",
      "{'clf__alpha': 0.5,\n",
      " 'vec__analyzer': 'word',\n",
      " 'vec__max_df': 0.8,\n",
      " 'vec__min_df': 3,\n",
      " 'vec__ngram_range': (1, 3)}\n",
      "\n",
      "\n",
      "Model with rank: 4\n",
      "Mean validation score: -0.535 (std: 0.003)\n",
      "Parameters:\n",
      "{'clf__alpha': 0.5,\n",
      " 'vec__analyzer': 'word',\n",
      " 'vec__max_df': 0.9,\n",
      " 'vec__min_df': 3,\n",
      " 'vec__ngram_range': (1, 3)}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "params_count_word = {\n",
    "    \"vec__ngram_range\": [(1,1), (1,2), (1,3)],\n",
    "    \"vec__analyzer\": ['word'],\n",
    "    \"vec__max_df\":[1.0, 0.9, 0.8, 0.7, 0.6, 0.5],\n",
    "    \"vec__min_df\":[2, 3, 5, 10]\n",
    "}\n",
    "\n",
    "params = {\n",
    "    \"clf__alpha\": [0.01, 0.1, 0.5, 1, 2]\n",
    "}\n",
    "\n",
    "\n",
    "params.update(params_count_word)\n",
    "\n",
    "for vec in [CountVectorizer, TfidfVectorizer]:\n",
    "    pipeline = Pipeline([\n",
    "        ('vec', vec()),\n",
    "        ('clf', MultinomialNB())\n",
    "    ])\n",
    "    \n",
    "    print(\"Using {}\".format(vec.__name__))\n",
    "    random_search = RandomizedSearchCV(pipeline, param_distributions=params, \n",
    "                                       scoring='neg_log_loss',\n",
    "                                       n_iter=20, cv=3, n_jobs=4)\n",
    "\n",
    "    random_search.fit(new_train.processed_text, train.author)\n",
    "    report(random_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Резултатите ни са най-добри до горната граница (2). Ще пробвам с малко по-големи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: -0.478 (std: 0.008)\n",
      "Parameters:\n",
      "{'clf__alpha': 2,\n",
      " 'vec__analyzer': 'word',\n",
      " 'vec__max_df': 0.8,\n",
      " 'vec__min_df': 3,\n",
      " 'vec__ngram_range': (1, 1)}\n",
      "\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: -0.480 (std: 0.007)\n",
      "Parameters:\n",
      "{'clf__alpha': 4,\n",
      " 'vec__analyzer': 'word',\n",
      " 'vec__max_df': 0.9,\n",
      " 'vec__min_df': 2,\n",
      " 'vec__ngram_range': (1, 1)}\n",
      "\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: -0.483 (std: 0.008)\n",
      "Parameters:\n",
      "{'clf__alpha': 5,\n",
      " 'vec__analyzer': 'word',\n",
      " 'vec__max_df': 0.5,\n",
      " 'vec__min_df': 2,\n",
      " 'vec__ngram_range': (1, 3)}\n",
      "\n",
      "\n",
      "Model with rank: 4\n",
      "Mean validation score: -0.498 (std: 0.008)\n",
      "Parameters:\n",
      "{'clf__alpha': 3,\n",
      " 'vec__analyzer': 'word',\n",
      " 'vec__max_df': 0.5,\n",
      " 'vec__min_df': 5,\n",
      " 'vec__ngram_range': (1, 2)}\n",
      "\n",
      "\n",
      "Model with rank: 5\n",
      "Mean validation score: -0.499 (std: 0.008)\n",
      "Parameters:\n",
      "{'clf__alpha': 4,\n",
      " 'vec__analyzer': 'word',\n",
      " 'vec__max_df': 0.6,\n",
      " 'vec__min_df': 5,\n",
      " 'vec__ngram_range': (1, 2)}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params_count_word = {\n",
    "    \"vec__ngram_range\": [(1,1), (1,2), (1,3)],\n",
    "    \"vec__analyzer\": ['word'],\n",
    "    \"vec__max_df\":[1.0, 0.9, 0.8, 0.7, 0.6, 0.5],\n",
    "    \"vec__min_df\":[2, 3, 5, 10]\n",
    "}\n",
    "\n",
    "params = {\n",
    "    \"clf__alpha\": range(2, 11)\n",
    "}\n",
    "\n",
    "\n",
    "params.update(params_count_word)\n",
    "\n",
    "def search():\n",
    "    pipeline = Pipeline([\n",
    "        ('vec', CountVectorizer()),\n",
    "        ('clf', MultinomialNB())\n",
    "    ])\n",
    "    \n",
    "    random_search = RandomizedSearchCV(pipeline, param_distributions=params, \n",
    "                                       scoring='neg_log_loss',\n",
    "                                       n_iter=20, cv=3, n_jobs=4)\n",
    "\n",
    "    random_search.fit(new_train.processed_text, train.author)\n",
    "    report(random_search.cv_results_)\n",
    "    \n",
    "\n",
    "search()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подбрахме някакви хиперпараметри и имаме обща идея какво можем да променим, за да си подобрим оценката.\n",
    "\n",
    "Време е да вкараме `LDA`. Първо без никакви хиперпараметри."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin056/.virtualenvs/machine-learning/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n",
      "/home/martin056/.virtualenvs/machine-learning/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n",
      "/home/martin056/.virtualenvs/machine-learning/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.06364151 -1.06972602 -1.07343668]\n",
      "mean:  -1.06893473718\n",
      "std:  0.00403781324269\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vec', CountVectorizer()),\n",
    "    ('lda', LatentDirichletAllocation()),\n",
    "    ('clf', MultinomialNB())\n",
    "])\n",
    "\n",
    "score_arr = cross_val_score(pipeline,\n",
    "                        new_train.processed_text,\n",
    "                        train.author,\n",
    "                        cv=3, \n",
    "                        n_jobs=3,\n",
    "                        scoring='neg_log_loss')\n",
    "\n",
    "print(score_arr)\n",
    "print(\"mean: \", score_arr.mean())\n",
    "print(\"std: \", score_arr.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Това е доста зле...\n",
    "\n",
    "Ще пробвам направо с оригиналните текстове - в лекцията видяхме, че това подобри резултата, макар че ме съмнява да помогне в случая."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin056/.virtualenvs/machine-learning/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n",
      "/home/martin056/.virtualenvs/machine-learning/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n",
      "/home/martin056/.virtualenvs/machine-learning/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.07466632 -1.06065831 -1.07202835]\n",
      "mean:  -1.06911766055\n",
      "std:  0.00607783817284\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vec', CountVectorizer()),\n",
    "    ('lda', LatentDirichletAllocation()),\n",
    "    ('clf', MultinomialNB())\n",
    "])\n",
    "\n",
    "score_arr = cross_val_score(pipeline,\n",
    "                        new_train.text,\n",
    "                        train.author,\n",
    "                        cv=3, \n",
    "                        n_jobs=3,\n",
    "                        scoring='neg_log_loss')\n",
    "\n",
    "print(score_arr)\n",
    "print(\"mean: \", score_arr.mean())\n",
    "print(\"std: \", score_arr.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Не се получава...\n",
    "\n",
    "Нека поне видим какви теми намира `LDA`.\n",
    "\n",
    "Но преди това ще променя `learning_method`, за да премахнем този warning (а и може това да подобри лошия ни score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.05114669 -1.01765627 -1.01981837]\n",
      "mean:  -1.02954044022\n",
      "std:  0.0153034016344\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vec', CountVectorizer()),\n",
    "    ('lda', LatentDirichletAllocation(learning_method='batch')),\n",
    "    ('clf', MultinomialNB())\n",
    "])\n",
    "\n",
    "score_arr = cross_val_score(pipeline,\n",
    "                            new_train.processed_text,\n",
    "                            train.author,\n",
    "                            cv=3,\n",
    "                            n_jobs=3,\n",
    "                            scoring='neg_log_loss')\n",
    "\n",
    "print(score_arr)\n",
    "print(\"mean: \", score_arr.mean())\n",
    "print(\"std: \", score_arr.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А сега да визуализираме темите."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic 0       topic 1       topic 2       topic 3       topic 4       \n",
      "--------      --------      --------      --------      --------      \n",
      "will          heart         door          the           see           \n",
      "upon          voice         room          upon          like          \n",
      "the           eye           the           one           it            \n",
      "say           now           house         foot          far           \n",
      "thus          one           open          street        come          \n",
      "make          love          find          two           eye           \n",
      "may           word          it            wall          earth         \n",
      "however       death         now           three         still         \n",
      "give          upon          within        light         look          \n",
      "mr            yet           thing         side          star          \n",
      "\n",
      "\n",
      "topic 5       topic 6       topic 7       topic 8       topic 9       \n",
      "--------      --------      --------      --------      --------      \n",
      "hand          say           raymond       the           but           \n",
      "little        old           will          an            even          \n",
      "the           know          return        one           one           \n",
      "head          take          the           now           know          \n",
      "de            man           take          thing         man           \n",
      "he            he            love          he            nature        \n",
      "eye           one           she           see           yet           \n",
      "one           upon          come          say           life          \n",
      "arm           nothing       perdita       year          seem          \n",
      "saw           well          one           like          thing         \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import mglearn\n",
    "\n",
    "vectorizer = CountVectorizer(max_df=0.5, max_features=10000)\n",
    "X = vectorizer.fit_transform(new_train.processed_text)\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=10, learning_method=\"batch\", max_iter=15, random_state=0)\n",
    "topics = lda.fit_transform(X)\n",
    "\n",
    "sorting = np.argsort(lda.components_, axis=1)[:, ::-1]\n",
    "feature_names = np.array(vectorizer.get_feature_names())\n",
    "mglearn.tools.print_topics(topics=range(10), feature_names=feature_names, sorting=sorting, topics_per_chunk=5, n_words=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Поне намерихме проблема\n",
    "\n",
    "Аз лично не мога да направя ясно разграничение между темите. Очаквах да има думи, като Франкенщайн или Ктхулу, което ясно щеше да покаже кой е авторът.\n",
    "\n",
    "За жалост такива думи в теми няма. Очевидно е, че `LDA` намира теми, но според мен те са близки за всички автори.\n",
    "\n",
    "Като се загледаме малко повече, всъщност можем да видим, че в тема 7 има 2 имена - `Raymond` и `Perdita`. Google ми подсказа, че това са герои от новелата `The Last Man` на Мери Шели. Също така, сещайки се за историята за Франкенщайн, можем да предполагаме, че тема 1 е именно за него, коет отново ни води до Мери Шели.\n",
    "\n",
    "От останалите теми не мисля, че можем да разберем нещо (а и не съм запознат с творчеството на авторите).\n",
    "\n",
    "`LDA` не ни помогна в подобряването на резултата, но поне опитахме..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
